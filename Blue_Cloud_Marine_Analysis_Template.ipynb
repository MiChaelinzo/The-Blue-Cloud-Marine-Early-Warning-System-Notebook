{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåä Blue-Cloud Marine Analysis Template\n",
    "\n",
    "This Jupyter notebook template provides Python equivalents to the Blue-Cloud Marine Notebook functions.\n",
    "\n",
    "## Setup and Installation\n",
    "\n",
    "First, install the required packages:\n",
    "```bash\n",
    "pip install -r python-requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gsw  # Gibbs SeaWater package\n",
    "from geopy.distance import geodesic\n",
    "from scipy.stats import entropy\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "print(\"üåä Blue-Cloud Marine Analysis Environment Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Marine Analysis Functions\n",
    "\n",
    "Python equivalents of the Blue-Cloud notebook functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarineAnalyzer:\n",
    "    \"\"\"Marine data analysis functions - Python equivalent of Blue-Cloud notebook helpers\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_density(temperature, salinity, pressure=0):\n",
    "        \"\"\"Calculate seawater density using GSW library\n",
    "        \n",
    "        Args:\n",
    "            temperature (float): Temperature in ¬∞C\n",
    "            salinity (float): Practical salinity (PSU)\n",
    "            pressure (float): Pressure in dbar (default: 0 for surface)\n",
    "            \n",
    "        Returns:\n",
    "            float: Density in kg/m¬≥\n",
    "        \"\"\"\n",
    "        return gsw.rho(salinity, temperature, pressure)\n",
    "    \n",
    "    @staticmethod\n",
    "    def find_thermocline_depth(temperature, depth):\n",
    "        \"\"\"Find thermocline depth from temperature gradient\n",
    "        \n",
    "        Args:\n",
    "            temperature (array): Temperature profile\n",
    "            depth (array): Corresponding depths\n",
    "            \n",
    "        Returns:\n",
    "            float: Thermocline depth in meters\n",
    "        \"\"\"\n",
    "        gradients = np.gradient(temperature, depth)\n",
    "        thermocline_idx = np.argmin(gradients)  # Most negative gradient\n",
    "        return depth[thermocline_idx]\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_shannon_diversity(species_counts):\n",
    "        \"\"\"Calculate Shannon diversity index\n",
    "        \n",
    "        Args:\n",
    "            species_counts (array): Array of species counts\n",
    "            \n",
    "        Returns:\n",
    "            float: Shannon diversity index\n",
    "        \"\"\"\n",
    "        proportions = np.array(species_counts) / np.sum(species_counts)\n",
    "        proportions = proportions[proportions > 0]  # Remove zeros\n",
    "        return entropy(proportions, base=np.e)\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_distance(coord1, coord2):\n",
    "        \"\"\"Calculate distance between two coordinates\n",
    "        \n",
    "        Args:\n",
    "            coord1 (tuple): (latitude, longitude) of first point\n",
    "            coord2 (tuple): (latitude, longitude) of second point\n",
    "            \n",
    "        Returns:\n",
    "            float: Distance in kilometers\n",
    "        \"\"\"\n",
    "        return geodesic(coord1, coord2).kilometers\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_ocean_data(max_depth=100, num_points=11):\n",
    "        \"\"\"Generate realistic oceanographic profile data\n",
    "        \n",
    "        Args:\n",
    "            max_depth (float): Maximum depth in meters\n",
    "            num_points (int): Number of data points\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary with temperature, salinity, depth, and coordinates\n",
    "        \"\"\"\n",
    "        depths = np.linspace(0, max_depth, num_points)\n",
    "        \n",
    "        # Realistic temperature profile (decreasing with depth)\n",
    "        surface_temp = 20 + np.random.normal(0, 2)\n",
    "        temperatures = surface_temp - (depths * 0.1) + np.random.normal(0, 0.5, len(depths))\n",
    "        \n",
    "        # Realistic salinity profile (slight increase with depth)\n",
    "        salinities = 35 + (depths * 0.001) + np.random.normal(0, 0.1, len(depths))\n",
    "        \n",
    "        # Random coordinates in North Atlantic\n",
    "        lat = 45 + np.random.uniform(-5, 10)\n",
    "        lon = -10 + np.random.uniform(-10, 20)\n",
    "        \n",
    "        return {\n",
    "            'temperature': temperatures,\n",
    "            'salinity': salinities,\n",
    "            'depth': depths,\n",
    "            'coordinates': {'lat': lat, 'lon': lon},\n",
    "            'timestamp': [datetime.now() - timedelta(hours=i) for i in range(len(depths))]\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_species_data(num_observations=10):\n",
    "        \"\"\"Generate sample species observation data\n",
    "        \n",
    "        Args:\n",
    "            num_observations (int): Number of observations to generate\n",
    "            \n",
    "        Returns:\n",
    "            list: List of species observation dictionaries\n",
    "        \"\"\"\n",
    "        species_list = ['Cod', 'Haddock', 'Herring', 'Mackerel', 'Tuna', 'Sardine', 'Anchovy', 'Sole', 'Plaice']\n",
    "        observations = []\n",
    "        \n",
    "        for i in range(num_observations):\n",
    "            obs = {\n",
    "                'species': np.random.choice(species_list),\n",
    "                'count': np.random.randint(1, 50),\n",
    "                'coordinates': {\n",
    "                    'lat': 45 + np.random.uniform(-5, 10),\n",
    "                    'lon': -10 + np.random.uniform(-10, 20)\n",
    "                },\n",
    "                'depth': np.random.uniform(0, 200),\n",
    "                'timestamp': datetime.now() - timedelta(days=np.random.randint(0, 30))\n",
    "            }\n",
    "            observations.append(obs)\n",
    "        \n",
    "        return observations\n",
    "    \n",
    "    @staticmethod\n",
    "    def analyze_oil_spill_risk(vessel_data):\n",
    "        \"\"\"Analyze vessel trajectory for oil spill risk\n",
    "        \n",
    "        Args:\n",
    "            vessel_data (list): List of vessel tracking dictionaries\n",
    "            \n",
    "        Returns:\n",
    "            dict: Risk assessment with score and factors\n",
    "        \"\"\"\n",
    "        if len(vessel_data) < 2:\n",
    "            return {'risk_score': 0, 'risk_factors': ['Insufficient data']}\n",
    "        \n",
    "        risk_score = 0\n",
    "        risk_factors = []\n",
    "        \n",
    "        # Check for sudden speed changes\n",
    "        speeds = [point['speed'] for point in vessel_data]\n",
    "        speed_changes = [abs(speeds[i] - speeds[i-1]) for i in range(1, len(speeds))]\n",
    "        \n",
    "        if max(speed_changes) > 5:\n",
    "            risk_score += 10\n",
    "            risk_factors.append('Sudden speed change detected')\n",
    "        \n",
    "        # Check for erratic course changes\n",
    "        headings = [point['heading'] for point in vessel_data]\n",
    "        heading_changes = [abs(headings[i] - headings[i-1]) for i in range(1, len(headings))]\n",
    "        \n",
    "        if max(heading_changes) > 45:\n",
    "            risk_score += 15\n",
    "            risk_factors.append('Erratic course changes detected')\n",
    "        \n",
    "        # Check proximity to sensitive areas (simplified)\n",
    "        sensitive_areas = [\n",
    "            {'lat': 60.0, 'lon': -3.0, 'name': 'North Sea Protected Area'},\n",
    "            {'lat': 43.5, 'lon': -8.0, 'name': 'Bay of Biscay Marine Park'}\n",
    "        ]\n",
    "        \n",
    "        for point in vessel_data:\n",
    "            for area in sensitive_areas:\n",
    "                distance = MarineAnalyzer.calculate_distance(\n",
    "                    (point['coordinates']['lat'], point['coordinates']['lon']),\n",
    "                    (area['lat'], area['lon'])\n",
    "                )\n",
    "                if distance < 50:  # Within 50km\n",
    "                    risk_score += 20\n",
    "                    risk_factors.append(f\"Near sensitive area: {area['name']}\")\n",
    "                    break\n",
    "        \n",
    "        return {\n",
    "            'risk_score': min(risk_score, 100),\n",
    "            'risk_factors': list(set(risk_factors))  # Remove duplicates\n",
    "        }\n",
    "\n",
    "# Create analyzer instance\n",
    "analyzer = MarineAnalyzer()\n",
    "print(\"‚úÖ Marine analysis functions loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåä Example 1: Oceanographic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample oceanographic data\n",
    "ocean_data = analyzer.generate_ocean_data(max_depth=100, num_points=21)\n",
    "\n",
    "print(\"üåä Oceanographic Profile Analysis\")\n",
    "print(f\"üìç Location: {ocean_data['coordinates']['lat']:.2f}¬∞N, {abs(ocean_data['coordinates']['lon']):.2f}¬∞W\")\n",
    "print(f\"üå°Ô∏è Temperature range: {min(ocean_data['temperature']):.1f} to {max(ocean_data['temperature']):.1f} ¬∞C\")\n",
    "print(f\"üßÇ Salinity range: {min(ocean_data['salinity']):.2f} to {max(ocean_data['salinity']):.2f} PSU\")\n",
    "\n",
    "# Find thermocline depth\n",
    "thermocline_depth = analyzer.find_thermocline_depth(ocean_data['temperature'], ocean_data['depth'])\n",
    "print(f\"üåä Thermocline depth: {thermocline_depth:.1f} meters\")\n",
    "\n",
    "# Calculate densities\n",
    "surface_density = analyzer.calculate_density(ocean_data['temperature'][0], ocean_data['salinity'][0])\n",
    "deep_density = analyzer.calculate_density(ocean_data['temperature'][-1], ocean_data['salinity'][-1])\n",
    "print(f\"üíß Surface density: {surface_density:.2f} kg/m¬≥\")\n",
    "print(f\"üíß Deep water density: {deep_density:.2f} kg/m¬≥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the oceanographic profile\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Temperature profile\n",
    "ax1.plot(ocean_data['temperature'], ocean_data['depth'], 'b-', linewidth=2, marker='o')\n",
    "ax1.axhline(y=thermocline_depth, color='r', linestyle='--', alpha=0.7, label=f'Thermocline ({thermocline_depth:.1f}m)')\n",
    "ax1.set_xlabel('Temperature (¬∞C)')\n",
    "ax1.set_ylabel('Depth (m)')\n",
    "ax1.set_title('üå°Ô∏è Temperature Profile')\n",
    "ax1.invert_yaxis()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Salinity profile\n",
    "ax2.plot(ocean_data['salinity'], ocean_data['depth'], 'g-', linewidth=2, marker='s')\n",
    "ax2.set_xlabel('Salinity (PSU)')\n",
    "ax2.set_ylabel('Depth (m)')\n",
    "ax2.set_title('üßÇ Salinity Profile')\n",
    "ax2.invert_yaxis()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Density profile\n",
    "densities = [analyzer.calculate_density(t, s) for t, s in zip(ocean_data['temperature'], ocean_data['salinity'])]\n",
    "ax3.plot(densities, ocean_data['depth'], 'purple', linewidth=2, marker='^')\n",
    "ax3.set_xlabel('Density (kg/m¬≥)')\n",
    "ax3.set_ylabel('Depth (m)')\n",
    "ax3.set_title('üíß Density Profile')\n",
    "ax3.invert_yaxis()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Temperature gradient\n",
    "gradients = np.gradient(ocean_data['temperature'], ocean_data['depth'])\n",
    "ax4.plot(gradients, ocean_data['depth'], 'orange', linewidth=2, marker='d')\n",
    "ax4.axhline(y=thermocline_depth, color='r', linestyle='--', alpha=0.7)\n",
    "ax4.set_xlabel('Temperature Gradient (¬∞C/m)')\n",
    "ax4.set_ylabel('Depth (m)')\n",
    "ax4.set_title('üìà Temperature Gradient')\n",
    "ax4.invert_yaxis()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üêü Example 2: Species Diversity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate species observation data\n",
    "species_data = analyzer.generate_species_data(25)\n",
    "\n",
    "print(\"üêü Species Diversity Analysis\")\n",
    "print(f\"üî¨ Total observations: {len(species_data)}\")\n",
    "\n",
    "# Create species count summary\n",
    "species_df = pd.DataFrame(species_data)\n",
    "species_summary = species_df.groupby('species')['count'].sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nüìä Species Distribution:\")\n",
    "for species, count in species_summary.items():\n",
    "    print(f\"  {species}: {count} individuals\")\n",
    "\n",
    "# Calculate Shannon diversity\n",
    "diversity = analyzer.calculate_shannon_diversity(species_summary.values)\n",
    "print(f\"\\nüìà Shannon Diversity Index: {diversity:.3f}\")\n",
    "\n",
    "# Calculate distances between observations\n",
    "if len(species_data) >= 2:\n",
    "    distances = []\n",
    "    for i in range(len(species_data)-1):\n",
    "        dist = analyzer.calculate_distance(\n",
    "            (species_data[i]['coordinates']['lat'], species_data[i]['coordinates']['lon']),\n",
    "            (species_data[i+1]['coordinates']['lat'], species_data[i+1]['coordinates']['lon'])\n",
    "        )\n",
    "        distances.append(dist)\n",
    "    \n",
    "    print(f\"\\nüìè Average distance between observations: {np.mean(distances):.2f} km\")\n",
    "    print(f\"üìè Maximum distance between observations: {max(distances):.2f} km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize species data\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Species abundance bar chart\n",
    "species_summary.plot(kind='bar', ax=ax1, color='skyblue')\n",
    "ax1.set_title('üêü Species Abundance')\n",
    "ax1.set_xlabel('Species')\n",
    "ax1.set_ylabel('Total Count')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Species distribution pie chart\n",
    "ax2.pie(species_summary.values, labels=species_summary.index, autopct='%1.1f%%', startangle=90)\n",
    "ax2.set_title('ü•ß Species Distribution')\n",
    "\n",
    "# Observation locations map\n",
    "lats = [obs['coordinates']['lat'] for obs in species_data]\n",
    "lons = [obs['coordinates']['lon'] for obs in species_data]\n",
    "counts = [obs['count'] for obs in species_data]\n",
    "\n",
    "scatter = ax3.scatter(lons, lats, c=counts, s=[c*3 for c in counts], alpha=0.6, cmap='viridis')\n",
    "ax3.set_xlabel('Longitude')\n",
    "ax3.set_ylabel('Latitude')\n",
    "ax3.set_title('üó∫Ô∏è Observation Locations')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter, ax=ax3, label='Count')\n",
    "\n",
    "# Depth distribution\n",
    "depths = [obs['depth'] for obs in species_data]\n",
    "ax4.hist(depths, bins=10, color='lightcoral', alpha=0.7, edgecolor='black')\n",
    "ax4.set_xlabel('Depth (m)')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.set_title('üìä Depth Distribution of Observations')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ¢Ô∏è Example 3: Oil Spill Risk Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate vessel tracking data with potential risk factors\n",
    "vessel_track = [\n",
    "    {'vessel_id': 'TANKER_001', 'coordinates': {'lat': 60.1, 'lon': -3.2}, 'speed': 12, 'heading': 45, 'timestamp': datetime.now()},\n",
    "    {'vessel_id': 'TANKER_001', 'coordinates': {'lat': 60.15, 'lon': -3.1}, 'speed': 8, 'heading': 90, 'timestamp': datetime.now()},\n",
    "    {'vessel_id': 'TANKER_001', 'coordinates': {'lat': 60.2, 'lon': -3.0}, 'speed': 15, 'heading': 135, 'timestamp': datetime.now()},\n",
    "    {'vessel_id': 'TANKER_001', 'coordinates': {'lat': 60.25, 'lon': -2.9}, 'speed': 3, 'heading': 180, 'timestamp': datetime.now()},\n",
    "    {'vessel_id': 'TANKER_001', 'coordinates': {'lat': 60.3, 'lon': -2.8}, 'speed': 18, 'heading': 225, 'timestamp': datetime.now()}\n",
    "]\n",
    "\n",
    "print(\"üö¢ Oil Spill Risk Assessment\")\n",
    "print(f\"üìä Analyzing trajectory with {len(vessel_track)} tracking points...\")\n",
    "\n",
    "# Perform risk assessment\n",
    "risk_assessment = analyzer.analyze_oil_spill_risk(vessel_track)\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è Risk Assessment Results:\")\n",
    "print(f\"üéØ Risk Score: {risk_assessment['risk_score']}/100\")\n",
    "print(f\"üìã Risk Factors:\")\n",
    "for factor in risk_assessment['risk_factors']:\n",
    "    print(f\"  ‚Ä¢ {factor}\")\n",
    "\n",
    "# Risk level interpretation\n",
    "risk_score = risk_assessment['risk_score']\n",
    "if risk_score > 50:\n",
    "    risk_level = \"üö® CRITICAL\"\n",
    "    recommendation = \"Immediate intervention required!\"\n",
    "elif risk_score > 30:\n",
    "    risk_level = \"‚ö†Ô∏è HIGH\"\n",
    "    recommendation = \"Immediate monitoring recommended\"\n",
    "elif risk_score > 15:\n",
    "    risk_level = \"‚ö° MODERATE\"\n",
    "    recommendation = \"Continue surveillance\"\n",
    "else:\n",
    "    risk_level = \"‚úÖ LOW\"\n",
    "    recommendation = \"Normal operations\"\n",
    "\n",
    "print(f\"\\n{risk_level} RISK: {recommendation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize vessel trajectory and risk analysis\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Vessel trajectory map\n",
    "lats = [point['coordinates']['lat'] for point in vessel_track]\n",
    "lons = [point['coordinates']['lon'] for point in vessel_track]\n",
    "speeds = [point['speed'] for point in vessel_track]\n",
    "\n",
    "# Plot trajectory with speed color coding\n",
    "scatter = ax1.scatter(lons, lats, c=speeds, s=100, cmap='RdYlBu_r', alpha=0.8)\n",
    "ax1.plot(lons, lats, 'k--', alpha=0.5, linewidth=1)\n",
    "ax1.set_xlabel('Longitude')\n",
    "ax1.set_ylabel('Latitude')\n",
    "ax1.set_title('üö¢ Vessel Trajectory (colored by speed)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter, ax=ax1, label='Speed (knots)')\n",
    "\n",
    "# Add sensitive area markers\n",
    "sensitive_areas = [\n",
    "    {'lat': 60.0, 'lon': -3.0, 'name': 'North Sea Protected Area'},\n",
    "    {'lat': 60.2, 'lon': -2.5, 'name': 'Marine Reserve'}\n",
    "]\n",
    "for area in sensitive_areas:\n",
    "    circle = plt.Circle((area['lon'], area['lat']), 0.3, color='red', alpha=0.3)\n",
    "    ax1.add_patch(circle)\n",
    "    ax1.text(area['lon'], area['lat']-0.1, area['name'], ha='center', fontsize=8)\n",
    "\n",
    "# Speed profile over time\n",
    "ax2.plot(range(len(speeds)), speeds, 'b-o', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Time Point')\n",
    "ax2.set_ylabel('Speed (knots)')\n",
    "ax2.set_title('‚ö° Speed Profile')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Heading changes\n",
    "headings = [point['heading'] for point in vessel_track]\n",
    "ax3.plot(range(len(headings)), headings, 'g-s', linewidth=2, markersize=8)\n",
    "ax3.set_xlabel('Time Point')\n",
    "ax3.set_ylabel('Heading (degrees)')\n",
    "ax3.set_title('üß≠ Heading Profile')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_ylim(0, 360)\n",
    "\n",
    "# Risk score visualization\n",
    "risk_categories = ['Speed\\nChanges', 'Course\\nChanges', 'Proximity\\nto Sensitive\\nAreas']\n",
    "risk_values = [10 if 'speed' in ' '.join(risk_assessment['risk_factors']).lower() else 0,\n",
    "               15 if 'course' in ' '.join(risk_assessment['risk_factors']).lower() else 0,\n",
    "               20 if 'sensitive' in ' '.join(risk_assessment['risk_factors']).lower() else 0]\n",
    "\n",
    "colors = ['red' if val > 0 else 'green' for val in risk_values]\n",
    "bars = ax4.bar(risk_categories, risk_values, color=colors, alpha=0.7)\n",
    "ax4.set_ylabel('Risk Score Contribution')\n",
    "ax4.set_title(f'üéØ Risk Factor Breakdown (Total: {risk_assessment[\"risk_score\"]})')\n",
    "ax4.set_ylim(0, 25)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, val in zip(bars, risk_values):\n",
    "    if val > 0:\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "                str(val), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Advanced Analysis: Combined Marine Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive marine environment assessment\n",
    "print(\"üåä Comprehensive Marine Environment Assessment\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Generate multiple datasets\n",
    "ocean_profiles = [analyzer.generate_ocean_data(max_depth=150) for _ in range(5)]\n",
    "species_observations = analyzer.generate_species_data(50)\n",
    "\n",
    "# Analyze temperature variations across profiles\n",
    "surface_temps = [profile['temperature'][0] for profile in ocean_profiles]\n",
    "thermocline_depths = [analyzer.find_thermocline_depth(profile['temperature'], profile['depth']) \n",
    "                     for profile in ocean_profiles]\n",
    "\n",
    "print(f\"üå°Ô∏è Surface Temperature Statistics:\")\n",
    "print(f\"   Mean: {np.mean(surface_temps):.2f}¬∞C\")\n",
    "print(f\"   Std:  {np.std(surface_temps):.2f}¬∞C\")\n",
    "print(f\"   Range: {min(surface_temps):.2f} - {max(surface_temps):.2f}¬∞C\")\n",
    "\n",
    "print(f\"\\nüåä Thermocline Depth Statistics:\")\n",
    "print(f\"   Mean: {np.mean(thermocline_depths):.1f}m\")\n",
    "print(f\"   Std:  {np.std(thermocline_depths):.1f}m\")\n",
    "print(f\"   Range: {min(thermocline_depths):.1f} - {max(thermocline_depths):.1f}m\")\n",
    "\n",
    "# Species diversity across different areas\n",
    "species_df = pd.DataFrame(species_observations)\n",
    "total_diversity = analyzer.calculate_shannon_diversity(\n",
    "    species_df.groupby('species')['count'].sum().values\n",
    ")\n",
    "\n",
    "print(f\"\\nüêü Biodiversity Assessment:\")\n",
    "print(f\"   Total species observed: {species_df['species'].nunique()}\")\n",
    "print(f\"   Total individuals: {species_df['count'].sum()}\")\n",
    "print(f\"   Shannon Diversity Index: {total_diversity:.3f}\")\n",
    "\n",
    "# Environmental quality index (simplified)\n",
    "temp_score = 100 - abs(np.mean(surface_temps) - 18) * 5  # Optimal around 18¬∞C\n",
    "diversity_score = min(total_diversity * 30, 100)  # Scale diversity\n",
    "depth_variability = np.std(thermocline_depths)\n",
    "stability_score = max(100 - depth_variability * 2, 0)  # Lower variability = more stable\n",
    "\n",
    "environmental_index = (temp_score + diversity_score + stability_score) / 3\n",
    "\n",
    "print(f\"\\nüåç Environmental Quality Index: {environmental_index:.1f}/100\")\n",
    "print(f\"   Temperature Score: {temp_score:.1f}/100\")\n",
    "print(f\"   Biodiversity Score: {diversity_score:.1f}/100\")\n",
    "print(f\"   Stability Score: {stability_score:.1f}/100\")\n",
    "\n",
    "if environmental_index > 80:\n",
    "    status = \"üü¢ EXCELLENT\"\n",
    "elif environmental_index > 60:\n",
    "    status = \"üü° GOOD\"\n",
    "elif environmental_index > 40:\n",
    "    status = \"üü† MODERATE\"\n",
    "else:\n",
    "    status = \"üî¥ POOR\"\n",
    "\n",
    "print(f\"\\n{status} - Marine Environment Status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Export Results\n",
    "\n",
    "Save your analysis results for further use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary report\n",
    "report = {\n",
    "    'analysis_date': datetime.now().isoformat(),\n",
    "    'oceanographic_data': {\n",
    "        'profiles_analyzed': len(ocean_profiles),\n",
    "        'surface_temperature_mean': float(np.mean(surface_temps)),\n",
    "        'surface_temperature_std': float(np.std(surface_temps)),\n",
    "        'thermocline_depth_mean': float(np.mean(thermocline_depths)),\n",
    "        'thermocline_depth_std': float(np.std(thermocline_depths))\n",
    "    },\n",
    "    'biodiversity_data': {\n",
    "        'total_observations': len(species_observations),\n",
    "        'species_count': int(species_df['species'].nunique()),\n",
    "        'total_individuals': int(species_df['count'].sum()),\n",
    "        'shannon_diversity': float(total_diversity)\n",
    "    },\n",
    "    'environmental_assessment': {\n",
    "        'overall_index': float(environmental_index),\n",
    "        'temperature_score': float(temp_score),\n",
    "        'biodiversity_score': float(diversity_score),\n",
    "        'stability_score': float(stability_score),\n",
    "        'status': status\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to JSON file\n",
    "import json\n",
    "with open('marine_analysis_report.json', 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "# Save species data to CSV\n",
    "species_df.to_csv('species_observations.csv', index=False)\n",
    "\n",
    "# Save oceanographic data\n",
    "ocean_summary = pd.DataFrame({\n",
    "    'profile_id': range(len(ocean_profiles)),\n",
    "    'surface_temperature': surface_temps,\n",
    "    'thermocline_depth': thermocline_depths,\n",
    "    'latitude': [p['coordinates']['lat'] for p in ocean_profiles],\n",
    "    'longitude': [p['coordinates']['lon'] for p in ocean_profiles]\n",
    "})\n",
    "ocean_summary.to_csv('oceanographic_summary.csv', index=False)\n",
    "\n",
    "print(\"üìÅ Analysis results saved:\")\n",
    "print(\"   ‚Ä¢ marine_analysis_report.json\")\n",
    "print(\"   ‚Ä¢ species_observations.csv\")\n",
    "print(\"   ‚Ä¢ oceanographic_summary.csv\")\n",
    "print(\"\\n‚úÖ Analysis complete! Results ready for further processing or sharing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîó Next Steps\n",
    "\n",
    "This template provides the foundation for marine data analysis in Python. You can extend it by:\n",
    "\n",
    "1. **Connecting to real data sources** (Copernicus Marine, EMODnet, etc.)\n",
    "2. **Adding more sophisticated analysis methods**\n",
    "3. **Creating interactive visualizations** with Plotly or Bokeh\n",
    "4. **Implementing machine learning models** for prediction\n",
    "5. **Building automated reporting systems**\n",
    "\n",
    "For more information, visit the [Blue-Cloud Marine Notebook documentation](README-NOTEBOOK.md)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}